# -*- coding: utf-8 -*-
"""QoE Optimization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sud5XTFB_0j5ZRe3ruCZKNsw9u10_g1o
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

df =pd.read_csv("drive/My Drive/pokemon.csv")
df.shape

df.columns

'''
Each variable belongs to a category of QoE Influence Factors (QoE IFs) that consists:
Video parameters from VLC video player (QoA) (3 to 10)
Network information (QoS) (11 to 12)
Device characteristics (QoD)(13 to 15)
User's profil (QoU) (16 to 18)
User feedback (QoF)(19 to 22)

--> Number of Instances :
-class 1 (MOS = 1): 92
-class 2 (MOS = 2): 119
-class 3 (MOS = 3): 244
-class 4 (MOS = 4): 787
-class 5 (MOS = 5): 300
--------------------------
10st (Ntype) attribute is class identifier for the used network type in the assessment: [1 BEING OLDER NETWORK TECH.]
• 1 : EDGE
• 2 : UMTS
• 3 : HSPA
• 4 : HSPAP
• 5 : LTE

11st (Noperator) attribute is class identifier for the network operator in France:  [DIFFERENT NETWORK PROVIDERS IN FRANCE.]
• 1 : SFR
• 2 : BOUYEGUES
• 3 : ORANGE
• 4 : FREE

14st (QoU_sex) User's gender.
• 0 -> Woman
• 1 -> man

15st (QoU_study) High user's level study
• 5 -> University
• 4 -> Secondary school
• 3 -> College
• 2 -> Premary school
• 1 -> Other

19st (MOS) Mean Opinion Scroe that a tester will give at the end of each video view. [1 BEING BAD 5 BEING EXCELLENT.]
• 5 -> Excellent
• 4 -> Good
• 3 -> Fair
• 2 -> Poor
• 1 -> Bad
'''

df.head()

df.shape

dups = df.duplicated()
df[dups]

df.isnull().sum()

df.drop(['user_id', 'id'], axis=1, inplace=True)

df.drop_duplicates(keep=False, inplace=True)    #Dups after dropping.

df.shape

print(df.dtypes)

df['QoD_model'].nunique()

df['QoD_os-version'].nunique()

de = pd.get_dummies(df, columns = ['QoD_model'])            #one hot encoding
de = pd.get_dummies(de, columns = ['QoD_os-version'])
print(de.shape)

print(de.columns)

'''      (SAVE TIME)

import matplotlib.pyplot as plt
import plotly.express as px

for col in de.columns:
  fig=px.histogram(de,x=col)
  fig.show()
'''

'''import matplotlib.pyplot as plt
import plotly.express as px

for col in de.columns:
  fig=px.box(de,y=col)
  fig.show()'''

import re
de = de.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))
de.head()

de.columns

# get the X and Y dataframes


X= de.iloc[:, :]
X=X.drop(['MOS'], axis=1)
y=de['MOS']

#df.drop(df.columns[[0, 4, 2]], axis=1, inplace=True)

from sklearn.model_selection import train_test_split

X.shape

X.shape
X.columns

# split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print('X_train : ')
print(X_train.head())
print('')
print('X_test : ')
print(X_test.head())
print('')
print('y_train : ')
print(y_train.head())
print('')
print('y_test : ')
print(y_test.head())

print('X_train : ')
print(X_train.shape)
print('')
print('X_test : ')
print(X_test.shape)
print('')
print('y_train : ')
print(y_train.shape)
print('')
print('y_test : ')
print(y_test.shape)

#SUPPORT VECTOR MACHINE CLASSIFIER

from sklearn import svm
model = svm.SVC(kernel='rbf', degree=2, C=10)
model.fit(X_train, y_train)
from sklearn import metrics
y_pred = model.predict(X_test)
print(y_pred)
print(metrics.confusion_matrix(y_pred, y))

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
import math
# Given values
Y_true = y_test  # Y_true = Y (original values)

# calculated values
Y_pred = model.predict(X_test)  # Y_pred = Y'

# Calculation of Mean Squared Error (MSE)
mse=mean_squared_error(Y_true,Y_pred)
rmse = math.sqrt(mse)
print(mse)
print("The difference between actual and predicted values", rmse)
print(mean_absolute_error(y_test, y_pred))

mean_absolute_error(y_test, y_pred)

#KNN CLASSIFIER
X = X_test
y =  y_test

# Instantiate and train the classifier
from sklearn.neighbors import KNeighborsClassifier
clf = KNeighborsClassifier(n_neighbors=10)
clf.fit(X, y)

# Check the results using metrics
from sklearn import metrics
y_pred = clf.predict(X)
print(y_pred)
print(metrics.confusion_matrix(y_pred, y))

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
import math
# Given values
Y_true = y_test  # Y_true = Y (original values)

# calculated values
Y_pred = clf.predict(X_test)  # Y_pred = Y'

# Calculation of Mean Squared Error (MSE)
mse=mean_squared_error(Y_true,Y_pred)
rmse = math.sqrt(mse)
print(mse)
print("The difference between actual and predicted values", rmse)
print(mean_absolute_error(y_test, y_pred))

#RANDOM FOREST CLASSIFIER

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification

rf = RandomForestClassifier(random_state=0, n_estimators=500)
rf.fit(X, y)
print(rf.predict(X_test))

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
import math
# Given values
Y_true = y_test  # Y_true = Y (original values)

# calculated values
Y_pred = rf.predict(X_test)  # Y_pred = Y'

# Calculation of Mean Squared Error (MSE)
mse=mean_squared_error(Y_true,Y_pred)
rmse = math.sqrt(mse)
print(mse)
print("The difference between actual and predicted values", rmse)
print(mean_absolute_error(y_test, y_pred))

#GRADIENT TREE BOOSTING CLASSIFIER

from sklearn.ensemble import GradientBoostingClassifier
gb = GradientBoostingClassifier(learning_rate=0.01, n_estimators=500)
gb.fit(X, y)
print(gb.predict(X_test))

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
import math
# Given values
Y_true = y_test  # Y_true = Y (original values)

# calculated values
Y_pred = gb.predict(X_test)  # Y_pred = Y'

# Calculation of Mean Squared Error (MSE)
mse=mean_squared_error(Y_true,Y_pred)
rmse = math.sqrt(mse)
print(mse)
print("The difference between actual and predicted values", rmse)
print(mean_absolute_error(y_test, y_pred))

#MLP CLASSIFIER

from sklearn.neural_network import MLPClassifier
from sklearn.datasets import make_classification

#X, y = make_classification(n_samples=100, random_state=1)

clf = MLPClassifier(learning_rate_init=0.001, hidden_layer_sizes=20, activation='relu').fit(X_train, y_train)
clf.predict_proba(X_test)
print(clf.predict(X_test))
clf.score(X_test, y_test)

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
import math
# Given values
Y_true = y_test  # Y_true = Y (original values)

# calculated values
Y_pred = clf.predict(X_test)  # Y_pred = Y'

# Calculation of Mean Squared Error (MSE)
mse=mean_squared_error(Y_true,Y_pred)
rmse = math.sqrt(mse)
print(mse)
print("The difference between actual and predicted values", rmse)
print(mean_absolute_error(y_test, y_pred))

#STOCHASTIC GRADIENT DESCENT CLASSIFIER
from sklearn.linear_model import SGDClassifier

sclf = SGDClassifier(loss="log_loss", penalty="l2", max_iter=1000, tol=1e-3)
sclf.fit(X, y)
print(sclf.predict(X_test))

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
import math
# Given values
Y_true = y_test  # Y_true = Y (original values)

# calculated values
Y_pred = sclf.predict(X_test)  # Y_pred = Y'

# Calculation of Mean Squared Error (MSE)
mse=mean_squared_error(Y_true,Y_pred)
rmse = math.sqrt(mse)
print(mse)
print("The difference between actual and predicted values", rmse)
print(mean_absolute_error(y_test, y_pred))

#DECISION TREE CLASSIFIER

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(min_samples_leaf=9, random_state=None)
dt.fit(X, y)
print(dt.predict(X_test))

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
import math
# Given values
Y_true = y_test  # Y_true = Y (original values)

# calculated values
Y_pred = dt.predict(X_test)  # Y_pred = Y'

# Calculation of Mean Squared Error (MSE)
mse=mean_squared_error(Y_true,Y_pred)
rmse = math.sqrt(mse)
print(mse)
print("The difference between actual and predicted values", rmse)
print(mean_absolute_error(y_test, y_pred))